<div class="home"><p><img align="left" src="../images/profilob.jpg" width="210" /></p>

<p>I am Antonio Norelli, a Computer Science PhD student at the Sapienza University of Rome working on AI and deep learning in the <a href="https://gladia.di.uniroma1.it/">GLADIA</a> research group, advised by <a href="https://scholar.google.com/citations?user=-EH4wBYAAAAJ&amp;hl=en">Emanuele Rodolà</a>.</p>

<p>Before joining the group, I studied physics (BSc), computer science (MSc), and pursued the <a href="https://web.uniroma1.it/sssas/en/sssas/ssas/about-us">SSAS</a> interdisciplinary honors program.
I worked as a remote Research Intern for <a href="https://www.spiketrap.io/">Spiketrap</a> (San Francisco, CA), and as an Applied Scientist Intern for the <a href="https://www.aboutamazon.eu/news/press-lounge/amazon-establishes-lablet-for-research-on-transparent-artificial-intelligence-in-tubingen">Amazon Lablet in Tübingen</a> (Germany).</p>

<hr />

<p><strong>What makes us humans?</strong> 
I am interested in the intelligence that accounts for the difference existing between human beings and the other animals.</p>

<p>To me this gap is on par to the one between life and non-life and is the consequence of a fundamental property of nature, that should be understood in terms of information processing.
Currently, I am persuaded that this intelligence coincides with our use of symbols, and that we shall model the mechanism through which humans link meaning to new signs. As when a scientist propose a new theory.</p>

<p><strong>Highlights of my research in this direction</strong></p>
<ul>
  <li>When a ML system becomes an artificial scientist: mastering the game of <a href="https://www.nickbentley.games/zendo-as-a-tool-for-teaching-the-scientific-method/">Zendo</a> with Transformers. <br /> <em>Explanatory Learning: Beyond Empiricism in Neural Networks</em>, 2022 [<a href="https://arxiv.org/abs/2201.10222">arXiv</a>] [<a href="https://github.com/gladia-research-group/explanatory-learning">code</a>] [<a href="https://twitter.com/noranta4/status/1493893787696906241?s=20">Twitter thread</a>] [<a href="https://twitter.com/yudapearl/status/1496048047805063168">Judea Pearl about this work</a>].</li>
  <li>The meaning was already there: connecting text and images without training a neural network to do so. <br /> <em>ASIF: Coupled Data Turns Unimodal Models to Multimodal Without Training</em>, 2022 [<a href="https://arxiv.org/abs/2210.01738">arXiv</a>] [code soon!] [<a href="https://twitter.com/smolix/status/1577640836124225537">Alex Smola about this work</a>].</li>
</ul>

<p><strong>Other featured research</strong></p>
<ul>
  <li>It happens that different neural networks trained on the same stuff learn intrinsically equivalent latent spaces. <br /> <em>Relative Representations Enable Zero-shot Latent Space Communication</em>, 2022 [<a href="https://arxiv.org/abs/2209.15430">arXiv</a>] [<a href="https://openreview.net/attachment?id=SrC-nwieGJ&amp;name=supplementary_material">code</a>] [<a href="https://openreview.net/forum?id=SrC-nwieGJ">Oral at ICLR23 with 8-8-10 reviews</a>].</li>
  <li>AlphaGo Zero for Othello. With two ideas to speed up the learning, and tested in a live match against a former world champion. <br /> <em>OLIVAW: Mastering Othello without Human Knowledge, nor a Penny</em>, 2022 [<a href="https://arxiv.org/abs/2103.17228">arXiv</a>] [<a href="https://youtu.be/kDVRuCI0HRc">Trailer of the match</a>].</li>
  <li>With the right geometric prior, 11 samples are enough to train a generative model for 3D shapes of humans or animals. <br /> <em>LIMP: Learning Latent Shape Representations with Metric Preservation Priors</em>, 2020 [<a href="https://arxiv.org/abs/2003.12283">arXiv</a>] [<a href="https://github.com/lcosmo/LIMP">code</a>] [Oral at ECCV 2020 (<a href="https://youtu.be/NPE_uey-dXo">2 min</a>, <a href="https://youtu.be/P4uxICQ3QXI">10min</a> video)].</li>
  <li>The task  with the <a href="https://mobile.twitter.com/noranta4/status/1512772956983906317">widest gap</a> between human and machine performance in BIG-bench, a collaborative effort to test Language Models. <br /> <em>Beyond the Imitation Game: Quantifying and Extrapolating the Capabilities of Language Models</em>, 2022 [<a href="https://arxiv.org/abs/2206.04615">arXiv</a>] [<a href="https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/symbol_interpretation">SIT task</a>].</li>
</ul>

<p>Check my <a href="https://scholar.google.com/citations?hl=en&amp;user=ADH8YWEAAAAJ">Google Scholar profile</a> for a complete list of my articles.</p>

<h3 id="featured-invited-talks">Featured invited Talks</h3>

<ul>
  <li>15/02/2023 Univeristy of Cambridge, CS department (UK 🇬🇧). <a href="https://talks.cam.ac.uk/talk/index/197683"><em>ASIF: Coupled Data Turns Unimodal Models to Multimodal Without Training</em></a></li>
  <li>12/09/2022 Tokyo Institute of Technology, CS department (Japan 🇯🇵). <a href="https://twitter.com/kanejaki/status/1566783524266733576?s=20&amp;t=qK7K6lM9TYpt_rzYwH7qYA"><em>From sound to metric priors: new paradigms for shape generation</em></a></li>
  <li>09/06/2022 Quantum Photonics, ONG (Virtual 🌐). <a href="https://twitter.com/qpclub1/status/1535368740422168576?s=20&amp;t=Nx6tckQnQxgJDcnaTX9z7g"><em>How to create an artificial scientist</em></a></li>
  <li>09/06/2022 Cassini Junior Workshop, French Embassy in Italy and SSAS (Rome 🇮🇹). <a href="https://sites.google.com/uniroma1.it/cassiniworkshop2020/home-page"><em>Towards a human-level artificial intelligence</em></a></li>
  <li>17/12/2021 International Symposium “Giornalismo e disinformazione”, UniPa (Palermo, 🇮🇹). <a href="https://www.unipa.it/dipartimenti/cultureesocieta/.content/documenti/Giornalismo-e-disinformazione-Programma.pdf"><em>Unire i puntini: meraviglie e limiti dei moderni sistemi di IA</em></a></li>
  <li>19/02/2019 Italian Association for Machine Learning, ML meetup (Rome 🇮🇹): <a href="https://www.eventbrite.it/e/biglietti-mlaws-meetup-the-italian-alphazero-ml-on-amazon-aperitech-54874582353"><em>The italian AlphaZero</em></a> [<a href="https://youtu.be/jjBE_yom1V4">360° clip</a>]</li>
</ul>

<h2 id="news">News</h2>

<ul>
  <li>20/09/2022 Invited speaker at the symposium “Saremo assimilati? Meraviglie, trappole e limiti dell’intelligenza artificiale”, organized by the italian Order of Journalists</li>
  <li>12/09/2022 Invited talk at the Tokyo Institute of Technology (Japan 🇯🇵): <a href="https://twitter.com/kanejaki/status/1566783524266733576?s=20&amp;t=qK7K6lM9TYpt_rzYwH7qYA"><em>From sound to metric priors: new paradigms for shape generation</em></a></li>
  <li>06/09/2022 <a href="https://dl.acm.org/doi/abs/10.1145/3514197.3549699"><em>Errare humanum est? a pilot study to evaluate the human-likeness of a AI othello playing agent</em></a> published at IVA 22</li>
  <li>05/09/2022 Presented our poster at the <a href="https://ml4evolang.github.io/">ml4evolang workshop</a> at the JCoLE conference in Kanazawa (Japan 🇯🇵): <a href="https://ml4evolang.github.io/static/program/ml4evolang-2022-program.pdf"><em>Learning to make sense out of ambiguous messages leads to language evolution, a simulation</em></a></li>
  <li>19/07/2022 Invited talk at DataScienceSeed (in italian, virtual): <a href="https://www.datascienceseed.com/2022/07/01/dss-online-16-explanatory-learning-puo-una-macchina-imparare-a-formulare-teorie/"><em>Explanatory Learning: può una macchina imparare a formulare teorie?</em></a></li>
  <li>15/07/2022 Back in Rome from Tübingen: end of my internship at Amazon (internship project: <a href="https://arxiv.org/abs/2210.01738">ASIF</a>)</li>
  <li>09/06/2022 Our <a href="https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/symbol_interpretation"><em>Symbol Interpretation Task</em></a> in <a href="https://arxiv.org/abs/2206.04615">BIG-bench</a> is the one with the <a href="https://mobile.twitter.com/noranta4/status/1512772956983906317">widest gap</a> between human and machine performance</li>
  <li>09/06/2022 Invited talk at Quantum Photonics (virtual): <a href="https://twitter.com/qpclub1/status/1535368740422168576?s=20&amp;t=Nx6tckQnQxgJDcnaTX9z7g"><em>How to create an artificial scientist</em></a></li>
  <li>27/04/2022 Guest lecture for the Computer Science course in Sapienza <a href="https://github.com/erodola/DLAI-s2-2022"><em>Deep Learning and applied AI</em></a>, titled <a href="https://github.com/erodola/DLAI-s2-2022/raw/main/11_invited/invited_lecture_Norelli.pdf"><em>Towards an artificial scientist</em></a></li>
  <li>08/03/2022 <a href="https://ieeexplore.ieee.org/document/9730005"><em>OLIVAW: Mastering Othello without Human Knowledge, nor a Penny</em></a> published on IEEE Transactions on Games</li>
  <li>25/01/2022 <a href="https://arxiv.org/abs/2201.10222"><em>Explanatory Learning: Beyond Empiricism in Neural Networks</em></a> is now on arXiv! <a href="https://mobile.twitter.com/noranta4/status/1493893787696906241">Twitter thread</a></li>
  <li>15/01/2022 Moving to Tübingen (Germany 🇩🇪) to start a research internship at Amazon Science where I will work with Francesco Locatello</li>
  <li>17/12/2021 Invited speaker at the International Symposium <a href="https://www.unipa.it/dipartimenti/cultureesocieta/.content/documenti/Giornalismo-e-disinformazione-Programma.pdf"><em>Giornalismo e disinformazione</em></a> at UniPa (Palermo, Italy 🇮🇹), panel <em>Umano, troppo umano? Intelligenza Artificiale e disinformazione</em></li>
  <li>13/11/2020 Contributed talk at <a href="https://melaniemitchell.me/SymposiumAgenda.pdf">AAAI Fall Symposium on Abstraction and Analogy in AI</a> (virtual): <a href="https://melaniemitchell.me/SymposiumAbstracts/Norelli.pdf"><em>The value of a rationalist approach in AI</em></a></li>
  <li>12/06/2020 Invited talk at Cassini Junior Workshop from French Embassy in Italy and SSAS (Rome 🇮🇹): <a href="https://sites.google.com/uniroma1.it/cassiniworkshop2020/home-page"><em>Towards a human-level artificial intelligence</em></a></li>
  <li>27/03/2020 <a href=""><em>LIMP: Learning latent shape representations with metric preservation priors</em></a> accepted as oral at ECCV-2020</li>
  <li>26/02/2020 Contributed talk at Technion - Israel Institute of Technology (Israel 🇮🇱) <a href="https://drive.google.com/file/d/1vXv0hB4DIWqnKtlF6E9QLFoTq8dilCyE/view?usp=sharing"><em>Learning deformable style transfer via differentiable
intrinsic distances</em></a></li>
  <li>01/11/2019 Started my PhD at Sapienza University of Rome advised by prof. Emanuele Rodolà</li>
  <li>19/02/2019 Invited talk at the ML meetup from the Italian Association for Machine Learning (Rome 🇮🇹): <a href="https://www.eventbrite.it/e/biglietti-mlaws-meetup-the-italian-alphazero-ml-on-amazon-aperitech-54874582353"><em>The italian AlphaZero</em></a></li>
</ul>



  

  <!-- Hide posts if front matter flag hide:true -->
  
  

  <!-- Sort posts by rank, then date -->
  
  
  

 
  

   <!-- Assemble final sorted posts array -->
  
  </div>